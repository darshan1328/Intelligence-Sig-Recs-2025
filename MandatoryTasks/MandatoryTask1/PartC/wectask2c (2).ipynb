{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[],"dockerImageVersionId":31154,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install transformers==4.28.0\nimport os\nimport torch\nfrom datasets import load_dataset\nfrom transformers import RobertaTokenizerFast, RobertaForQuestionAnswering\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-10-23T17:22:59.276457Z","iopub.execute_input":"2025-10-23T17:22:59.276622Z","iopub.status.idle":"2025-10-23T17:23:19.477271Z","shell.execute_reply.started":"2025-10-23T17:22:59.276605Z","shell.execute_reply":"2025-10-23T17:23:19.476669Z"}},"outputs":[{"name":"stdout","text":"Collecting transformers==4.28.0\n  Downloading transformers-4.28.0-py3-none-any.whl.metadata (109 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m110.0/110.0 kB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers==4.28.0) (3.19.1)\nCollecting huggingface-hub<1.0,>=0.11.0 (from transformers==4.28.0)\n  Downloading huggingface_hub-0.36.0-py3-none-any.whl.metadata (14 kB)\nRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers==4.28.0) (1.26.4)\nRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers==4.28.0) (25.0)\nRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers==4.28.0) (6.0.3)\nRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers==4.28.0) (2025.9.18)\nRequirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers==4.28.0) (2.32.5)\nCollecting tokenizers!=0.11.3,<0.14,>=0.11.1 (from transformers==4.28.0)\n  Downloading tokenizers-0.13.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\nRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers==4.28.0) (4.67.1)\nRequirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.11.0->transformers==4.28.0) (2025.9.0)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.11.0->transformers==4.28.0) (4.15.0)\nRequirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.11.0->transformers==4.28.0) (1.1.10)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers==4.28.0) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers==4.28.0) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers==4.28.0) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers==4.28.0) (2025.2.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers==4.28.0) (2022.2.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers==4.28.0) (2.4.1)\nRequirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers==4.28.0) (3.4.3)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers==4.28.0) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers==4.28.0) (2.5.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers==4.28.0) (2025.8.3)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17->transformers==4.28.0) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17->transformers==4.28.0) (2022.2.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy>=1.17->transformers==4.28.0) (1.4.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy>=1.17->transformers==4.28.0) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy>=1.17->transformers==4.28.0) (2024.2.0)\nDownloading transformers-4.28.0-py3-none-any.whl (7.0 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.0/7.0 MB\u001b[0m \u001b[31m25.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m:00:01\u001b[0m\n\u001b[?25hDownloading huggingface_hub-0.36.0-py3-none-any.whl (566 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m566.1/566.1 kB\u001b[0m \u001b[31m34.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading tokenizers-0.13.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.8 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m114.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n\u001b[?25hInstalling collected packages: tokenizers, huggingface-hub, transformers\n  Attempting uninstall: tokenizers\n    Found existing installation: tokenizers 0.21.2\n    Uninstalling tokenizers-0.21.2:\n      Successfully uninstalled tokenizers-0.21.2\n  Attempting uninstall: huggingface-hub\n    Found existing installation: huggingface-hub 1.0.0rc2\n    Uninstalling huggingface-hub-1.0.0rc2:\n      Successfully uninstalled huggingface-hub-1.0.0rc2\n  Attempting uninstall: transformers\n    Found existing installation: transformers 4.53.3\n    Uninstalling transformers-4.53.3:\n      Successfully uninstalled transformers-4.53.3\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\ndatasets 4.1.1 requires pyarrow>=21.0.0, but you have pyarrow 19.0.1 which is incompatible.\nkaggle-environments 1.18.0 requires transformers>=4.33.1, but you have transformers 4.28.0 which is incompatible.\nsentence-transformers 4.1.0 requires transformers<5.0.0,>=4.41.0, but you have transformers 4.28.0 which is incompatible.\ngradio 5.38.1 requires pydantic<2.12,>=2.0, but you have pydantic 2.12.0a1 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed huggingface-hub-0.36.0 tokenizers-0.13.3 transformers-4.28.0\n","output_type":"stream"}],"execution_count":1},{"cell_type":"markdown","source":"Loading the NewsQA dataset","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nsplits = {'train': 'data/train-00000-of-00001-ec54fbe500fc3b5c.parquet', 'validation': 'data/validation-00000-of-00001-3cf888b12fff1dd6.parquet'}\ndf = pd.read_parquet(\"hf://datasets/lucadiliello/newsqa/\" + splits[\"train\"])\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-23T17:23:41.120118Z","iopub.execute_input":"2025-10-23T17:23:41.120749Z","iopub.status.idle":"2025-10-23T17:23:50.083070Z","shell.execute_reply.started":"2025-10-23T17:23:41.120725Z","shell.execute_reply":"2025-10-23T17:23:50.082435Z"}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"df.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-23T17:23:57.118395Z","iopub.execute_input":"2025-10-23T17:23:57.119135Z","iopub.status.idle":"2025-10-23T17:23:57.148284Z","shell.execute_reply.started":"2025-10-23T17:23:57.119114Z","shell.execute_reply":"2025-10-23T17:23:57.147661Z"}},"outputs":[{"execution_count":3,"output_type":"execute_result","data":{"text/plain":"                                             context  \\\n0  NEW DELHI, India (CNN) -- A high court in nort...   \n1  NEW DELHI, India (CNN) -- A high court in nort...   \n2  NEW DELHI, India (CNN) -- A high court in nort...   \n3  NEW DELHI, India (CNN) -- A high court in nort...   \n4  NEW DELHI, India (CNN) -- A high court in nort...   \n\n                                            question  \\\n0          What was the amount of children murdered?   \n1               When was Pandher sentenced to death?   \n2  The court aquitted Moninder Singh Pandher of w...   \n3                                  who was acquitted   \n4                                  who was sentenced   \n\n                    answers                               key  \\\n0                      [19]  da0e6b66e04d439fa1ba23c32de07e50   \n1               [February.]  724f6eb9a2814e4fb2d7d8e4de846073   \n2         [rape and murder]  d64cbb90e5134081acfa83d3e702408c   \n3  [Moninder Singh Pandher]  fd7177ee6f1f4d62becd983a0305f503   \n4  [Moninder Singh Pandher]  cd25c69f631349748ccdeccaace66463   \n\n                             labels  \n0  [{'end': [295], 'start': [294]}]  \n1  [{'end': [269], 'start': [261]}]  \n2  [{'end': [638], 'start': [624]}]  \n3  [{'end': [216], 'start': [195]}]  \n4  [{'end': [216], 'start': [195]}]  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>context</th>\n      <th>question</th>\n      <th>answers</th>\n      <th>key</th>\n      <th>labels</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>NEW DELHI, India (CNN) -- A high court in nort...</td>\n      <td>What was the amount of children murdered?</td>\n      <td>[19]</td>\n      <td>da0e6b66e04d439fa1ba23c32de07e50</td>\n      <td>[{'end': [295], 'start': [294]}]</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>NEW DELHI, India (CNN) -- A high court in nort...</td>\n      <td>When was Pandher sentenced to death?</td>\n      <td>[February.]</td>\n      <td>724f6eb9a2814e4fb2d7d8e4de846073</td>\n      <td>[{'end': [269], 'start': [261]}]</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>NEW DELHI, India (CNN) -- A high court in nort...</td>\n      <td>The court aquitted Moninder Singh Pandher of w...</td>\n      <td>[rape and murder]</td>\n      <td>d64cbb90e5134081acfa83d3e702408c</td>\n      <td>[{'end': [638], 'start': [624]}]</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>NEW DELHI, India (CNN) -- A high court in nort...</td>\n      <td>who was acquitted</td>\n      <td>[Moninder Singh Pandher]</td>\n      <td>fd7177ee6f1f4d62becd983a0305f503</td>\n      <td>[{'end': [216], 'start': [195]}]</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>NEW DELHI, India (CNN) -- A high court in nort...</td>\n      <td>who was sentenced</td>\n      <td>[Moninder Singh Pandher]</td>\n      <td>cd25c69f631349748ccdeccaace66463</td>\n      <td>[{'end': [216], 'start': [195]}]</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":3},{"cell_type":"code","source":"import pandas as pd\nfrom datasets import Dataset, DatasetDict\n\nsplits = {\n    'train': 'data/train-00000-of-00001-ec54fbe500fc3b5c.parquet',\n    'validation': 'data/validation-00000-of-00001-3cf888b12fff1dd6.parquet'\n}\ndf_train = pd.read_parquet(\"hf://datasets/lucadiliello/newsqa/\" + splits[\"train\"])\ndf_val   = pd.read_parquet(\"hf://datasets/lucadiliello/newsqa/\" + splits[\"validation\"])\ndf_train = df_train\n\ndef df_to_flat_dataset(df):\n    flat = []\n    for _, row in df.iterrows():\n        context = str(row[\"context\"])\n        question = str(row[\"question\"])\n        answer_text = str(row[\"answers\"][0])\n        answer_start = int(row[\"labels\"][0][\"start\"][0])\n        qid = str(row[\"key\"])\n        flat.append({\n            \"context\": context,\n            \"question\": question,\n            \"answers\": [{\"text\": answer_text, \"answer_start\": answer_start}],\n            \"id\": qid\n        })\n    return flat\n\ntrain_dataset = Dataset.from_list(df_to_flat_dataset(df_train))\nval_dataset   = Dataset.from_list(df_to_flat_dataset(df_val))\nraw_datasets = DatasetDict({\"train\": train_dataset, \"validation\": val_dataset})\n\nprint(raw_datasets)\nprint(raw_datasets[\"train\"][0])\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-23T17:24:39.889048Z","iopub.execute_input":"2025-10-23T17:24:39.889723Z","iopub.status.idle":"2025-10-23T17:24:49.246921Z","shell.execute_reply.started":"2025-10-23T17:24:39.889702Z","shell.execute_reply":"2025-10-23T17:24:49.246306Z"}},"outputs":[{"name":"stdout","text":"DatasetDict({\n    train: Dataset({\n        features: ['context', 'question', 'answers', 'id'],\n        num_rows: 74160\n    })\n    validation: Dataset({\n        features: ['context', 'question', 'answers', 'id'],\n        num_rows: 4212\n    })\n})\n{'context': 'NEW DELHI, India (CNN) -- A high court in northern India on Friday acquitted a wealthy businessman facing the death sentence for the killing of a teen in a case dubbed \"the house of horrors.\"\\n\\n\\n\\nMoninder Singh Pandher was sentenced to death by a lower court in February.\\n\\n\\n\\nThe teen was one of 19 victims -- children and young women -- in one of the most gruesome serial killings in India in recent years.\\n\\n\\n\\nThe Allahabad high court has acquitted Moninder Singh Pandher, his lawyer Sikandar B. Kochar told CNN.\\n\\n\\n\\nPandher and his domestic employee Surinder Koli were sentenced to death in February by a lower court for the rape and murder of the 14-year-old.\\n\\n\\n\\nThe high court upheld Koli\\'s death sentence, Kochar said.\\n\\n\\n\\nThe two were arrested two years ago after body parts packed in plastic bags were found near their home in Noida, a New Delhi suburb. Their home was later dubbed a \"house of horrors\" by the Indian media.\\n\\n\\n\\nPandher was not named a main suspect by investigators initially, but was summoned as co-accused during the trial, Kochar said.\\n\\n\\n\\nKochar said his client was in Australia when the teen was raped and killed.\\n\\n\\n\\nPandher faces trial in the remaining 18 killings and could remain in custody, the attorney said.', 'question': 'What was the amount of children murdered?', 'answers': [{'answer_start': 294, 'text': '19'}], 'id': 'da0e6b66e04d439fa1ba23c32de07e50'}\n","output_type":"stream"}],"execution_count":4},{"cell_type":"code","source":"from transformers import RobertaTokenizerFast\n\nMODEL_NAME = \"deepset/roberta-base-squad2\"\ntokenizer = RobertaTokenizerFast.from_pretrained(MODEL_NAME)\n\nMAX_LENGTH = 256\nDOC_STRIDE = 64\nNUM_PROC = None \n\ndef prepare_features(examples):\n    tokenized_list = {\n        \"input_ids\": [],\n        \"attention_mask\": [],\n        \"start_positions\": [],\n        \"end_positions\": []\n    }\n\n    for i in range(len(examples[\"context\"])):\n        context = examples[\"context\"][i]\n        question = examples[\"question\"][i]\n        answer = examples[\"answers\"][i][0]\n        answer_text = answer[\"text\"]\n        answer_start = answer[\"answer_start\"]\n        answer_end = answer_start + len(answer_text)\n\n        encodings = tokenizer(\n            question,\n            context,\n            truncation=\"only_second\",\n            max_length=MAX_LENGTH,\n            stride=DOC_STRIDE,\n            return_overflowing_tokens=True,\n            return_offsets_mapping=True,\n            padding=\"max_length\"\n        )\n\n        overflow_sample_mapping = encodings.pop(\"overflow_to_sample_mapping\")\n        offset_mapping = encodings.pop(\"offset_mapping\")\n\n        for j, offsets in enumerate(offset_mapping):\n            input_ids = encodings[\"input_ids\"][j]\n            cls_index = input_ids.index(tokenizer.cls_token_id)\n\n            start_token, end_token = cls_index, cls_index\n            for idx, (start_off, end_off) in enumerate(offsets):\n                if start_off <= answer_start < end_off:\n                    start_token = idx\n                if start_off < answer_end <= end_off:\n                    end_token = idx\n\n            tokenized_list[\"input_ids\"].append(input_ids)\n            tokenized_list[\"attention_mask\"].append(encodings[\"attention_mask\"][j])\n            tokenized_list[\"start_positions\"].append(start_token)\n            tokenized_list[\"end_positions\"].append(end_token)\n\n    return tokenized_list\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-23T17:25:57.715747Z","iopub.execute_input":"2025-10-23T17:25:57.716053Z","iopub.status.idle":"2025-10-23T17:25:59.523319Z","shell.execute_reply.started":"2025-10-23T17:25:57.716038Z","shell.execute_reply":"2025-10-23T17:25:59.522684Z"}},"outputs":[{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/huggingface_hub/file_download.py:942: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n  warnings.warn(\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/79.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8459e9f6b99a4b55b380fde997e54c1d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.json: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5c8e33cc9fe747a89332fa44edf59c2a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"merges.txt: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1ec3d01d6793449684ef2f1b4782053c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/772 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"55821bd070624bcf88426e3164b920ff"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/571 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b82e841405ed4136a39489d2257bad3a"}},"metadata":{}}],"execution_count":5},{"cell_type":"code","source":"\ntokenized_datasets = raw_datasets.map(\n    prepare_features,\n    batched=True,\n    num_proc=NUM_PROC, \n    remove_columns=raw_datasets[\"train\"].column_names\n)\n\nprint(tokenized_datasets)\nprint(tokenized_datasets[\"train\"][0])\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-23T17:26:15.173875Z","iopub.execute_input":"2025-10-23T17:26:15.174168Z","iopub.status.idle":"2025-10-23T17:30:07.775895Z","shell.execute_reply.started":"2025-10-23T17:26:15.174148Z","shell.execute_reply":"2025-10-23T17:30:07.775135Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/74160 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"846a05dd9c7d45149eafc344633b33c5"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/4212 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c5735a0d693645feb7358cc4cdbe290c"}},"metadata":{}},{"name":"stdout","text":"DatasetDict({\n    train: Dataset({\n        features: ['input_ids', 'attention_mask', 'start_positions', 'end_positions'],\n        num_rows: 287260\n    })\n    validation: Dataset({\n        features: ['input_ids', 'attention_mask', 'start_positions', 'end_positions'],\n        num_rows: 16232\n    })\n})\n{'input_ids': [0, 2264, 21, 5, 1280, 9, 408, 9694, 116, 2, 2, 5341, 16286, 15473, 6, 666, 36, 16256, 43, 480, 83, 239, 461, 11, 3285, 666, 15, 273, 17871, 10, 8581, 8950, 2114, 5, 744, 3645, 13, 5, 2429, 9, 10, 6066, 11, 10, 403, 9260, 22, 627, 790, 9, 30178, 72, 50140, 50118, 50118, 17312, 7026, 3657, 13163, 1843, 21, 4018, 7, 744, 30, 10, 795, 461, 11, 902, 4, 50140, 50118, 50118, 133, 6066, 21, 65, 9, 753, 1680, 480, 408, 8, 664, 390, 480, 11, 65, 9, 5, 144, 25988, 13603, 8798, 11, 666, 11, 485, 107, 4, 50140, 50118, 50118, 133, 20788, 7826, 239, 461, 34, 17871, 3385, 7026, 3657, 13163, 1843, 6, 39, 2470, 17209, 463, 271, 163, 4, 14296, 271, 174, 3480, 4, 50140, 50118, 50118, 45741, 1843, 8, 39, 1897, 3200, 6544, 7026, 229, 6483, 58, 4018, 7, 744, 11, 902, 30, 10, 795, 461, 13, 5, 5345, 8, 1900, 9, 5, 501, 12, 180, 12, 279, 4, 50140, 50118, 50118, 133, 239, 461, 14817, 229, 6483, 18, 744, 3645, 6, 14296, 271, 26, 4, 50140, 50118, 50118, 133, 80, 58, 1128, 80, 107, 536, 71, 809, 1667, 6515, 11, 4136, 5565, 58, 303, 583, 49, 184, 11, 440, 4347, 6, 10, 188, 3534, 11906, 4, 2667, 184, 21, 423, 9260, 10, 22, 3138, 9, 30178, 113, 30, 5, 1362, 433, 4, 50140, 50118, 50118, 45741, 1843, 21, 45, 1440, 10, 1049, 1985, 30, 3725, 3225, 6, 53, 21, 17323, 25, 1029, 12, 7904, 6199, 148, 5, 1500, 2], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'start_positions': 79, 'end_positions': 79}\n","output_type":"stream"}],"execution_count":6},{"cell_type":"code","source":"import torch\nfrom transformers import RobertaForQuestionAnswering\n\nmodel = RobertaForQuestionAnswering.from_pretrained(MODEL_NAME)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-23T17:30:15.570444Z","iopub.execute_input":"2025-10-23T17:30:15.571040Z","iopub.status.idle":"2025-10-23T17:30:20.621982Z","shell.execute_reply.started":"2025-10-23T17:30:15.571019Z","shell.execute_reply":"2025-10-23T17:30:20.621139Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/496M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"751751cad3ac4e81a0a8b37b89d05f86"}},"metadata":{}}],"execution_count":7},{"cell_type":"code","source":"from transformers import TrainingArguments, Trainer\n\nargs = TrainingArguments(\n    output_dir=\"./newsqa_fast\",\n    evaluation_strategy=\"epoch\",\n    save_strategy=\"no\",\n    learning_rate=3e-5,\n    per_device_train_batch_size=8,\n    num_train_epochs=0.3,\n    weight_decay=0.01,\n    fp16=True,\n    logging_steps=10000,\n    report_to=\"none\",\n    disable_tqdm=True,\n)\n\n\ntrainer = Trainer(\n    model=model,\n    args=args,\n    train_dataset=tokenized_datasets[\"train\"],\n    eval_dataset=tokenized_datasets[\"validation\"],\n)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-23T17:39:11.127027Z","iopub.execute_input":"2025-10-23T17:39:11.127378Z","iopub.status.idle":"2025-10-23T17:39:11.138603Z","shell.execute_reply.started":"2025-10-23T17:39:11.127348Z","shell.execute_reply":"2025-10-23T17:39:11.137886Z"}},"outputs":[],"execution_count":10},{"cell_type":"code","source":"trainer.train()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-23T17:39:13.995993Z","iopub.execute_input":"2025-10-23T17:39:13.996626Z","iopub.status.idle":"2025-10-23T18:21:08.527379Z","shell.execute_reply.started":"2025-10-23T17:39:13.996599Z","shell.execute_reply":"2025-10-23T18:21:08.526759Z"}},"outputs":[{"name":"stdout","text":"{'loss': 0.8558, 'learning_rate': 2.1776663881927038e-06, 'epoch': 0.28}\n{'eval_loss': 0.800955593585968, 'eval_runtime': 129.5208, 'eval_samples_per_second': 125.323, 'eval_steps_per_second': 15.665, 'epoch': 0.3}\n{'train_runtime': 2514.5087, 'train_samples_per_second': 34.272, 'train_steps_per_second': 4.284, 'train_loss': 0.8535968409068824, 'epoch': 0.3}\n","output_type":"stream"},{"execution_count":11,"output_type":"execute_result","data":{"text/plain":"TrainOutput(global_step=10773, training_loss=0.8535968409068824, metrics={'train_runtime': 2514.5087, 'train_samples_per_second': 34.272, 'train_steps_per_second': 4.284, 'train_loss': 0.8535968409068824, 'epoch': 0.3})"},"metadata":{}}],"execution_count":11},{"cell_type":"code","source":"trainer.save_model(\"./newsqa_roberta_final\")  # saves model + config\ntokenizer.save_pretrained(\"./newsqa_roberta_final\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-23T18:21:21.291838Z","iopub.execute_input":"2025-10-23T18:21:21.292439Z","iopub.status.idle":"2025-10-23T18:21:22.131488Z","shell.execute_reply.started":"2025-10-23T18:21:21.292417Z","shell.execute_reply":"2025-10-23T18:21:22.130853Z"}},"outputs":[{"execution_count":12,"output_type":"execute_result","data":{"text/plain":"('./newsqa_roberta_final/tokenizer_config.json',\n './newsqa_roberta_final/special_tokens_map.json',\n './newsqa_roberta_final/vocab.json',\n './newsqa_roberta_final/merges.txt',\n './newsqa_roberta_final/added_tokens.json',\n './newsqa_roberta_final/tokenizer.json')"},"metadata":{}}],"execution_count":12},{"cell_type":"code","source":"import torch\n\ndef answer_question(model, tokenizer, question, context, max_len=256):\n    model.eval()\n    inputs = tokenizer(\n        question,\n        context,\n        return_tensors=\"pt\",\n        truncation=\"only_second\",\n        max_length=max_len\n    ).to(model.device)\n\n    with torch.no_grad():\n        outputs = model(**inputs)\n\n    start_idx = torch.argmax(outputs.start_logits)\n    end_idx   = torch.argmax(outputs.end_logits)\n\n    answer_ids = inputs[\"input_ids\"][0][start_idx:end_idx+1]\n    answer = tokenizer.decode(answer_ids, skip_special_tokens=True)\n    return answer\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-23T18:21:25.395777Z","iopub.execute_input":"2025-10-23T18:21:25.396277Z","iopub.status.idle":"2025-10-23T18:21:25.401136Z","shell.execute_reply.started":"2025-10-23T18:21:25.396254Z","shell.execute_reply":"2025-10-23T18:21:25.400558Z"}},"outputs":[],"execution_count":13},{"cell_type":"code","source":"context = \"\"\"The Amazon rainforest is often called the \"lungs of the Earth\" because it produces a large portion of the planet’s oxygen. However, deforestation has caused a significant decrease in its size over the past decades.\"\"\"\n\nquestion = \"Why is the Amazon rainforest called the lungs of the Earth?\"\n\nprint(answer_question(model, tokenizer, question, context))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-23T18:27:25.319910Z","iopub.execute_input":"2025-10-23T18:27:25.320694Z","iopub.status.idle":"2025-10-23T18:27:25.338279Z","shell.execute_reply.started":"2025-10-23T18:27:25.320666Z","shell.execute_reply":"2025-10-23T18:27:25.337715Z"}},"outputs":[{"name":"stdout","text":" it produces a large portion of the planet’s oxygen.\n","output_type":"stream"}],"execution_count":15}]}